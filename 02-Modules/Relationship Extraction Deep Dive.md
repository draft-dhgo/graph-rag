---
title: Relationship Extraction Deep Dive
tags:
  - deep-dive
  - relationship-extraction
  - llm
  - knowledge-graph
  - implementation
created: 2025-01-12
type: deep-dive
links:
  - [[Relationship]]
  - [[Entity Extraction Deep Dive]]
  - [[Index Module]]
---

# Relationship Extraction Deep Dive

ê´€ê³„ ì¶”ì¶œ(Relationship Extraction)ì€ ì¶”ì¶œëœ ì—”í‹°í‹° ê°„ì˜ ì˜ë¯¸ ìˆëŠ” ì—°ê²°ì„ ì‹ë³„í•˜ê³ , ì´ë¥¼ ê°€ì¤‘ì¹˜ê°€ ìˆëŠ” ê·¸ë˜í”„ ì—ì§€ë¡œ ë³€í™˜í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì…ë‹ˆë‹¤.

## ëª©ì°¨

### 1. ê°œìš”
- [ê´€ê³„ ì¶”ì¶œì˜ ëª©ì ](#-ê´€ê³„-ì¶”ì¶œì˜-ëª©ì )
- [ë¹—ëŒ€ì–´ ë³´ê¸°: ì†Œì…œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„](#-ë¹—ëŒ€ì–´-ë³´ê¸°-ì†Œì…œ-ë„¤íŠ¸ì›Œí¬-ë¶„ì„)

### 2. ì•„í‚¤í…ì²˜
- [ì¶”ì¶œ ì•„í‚¤í…ì²˜](#-ì¶”ì¶œ-ì•„í‚¤í…ì²˜)
- [ê´€ê³„ ê°ì§€ ë°©ë²•](#-ê´€ê³„-ê°ì§€-ë°©ë²•)

### 3. ê´€ê³„ ìœ í˜•
- [ê´€ê³„ ìœ í˜• ë¶„ë¥˜](#-ê´€ê³„-ìœ í˜•-ë¶„ë¥˜)
- [ë„ë©”ì¸ë³„ ê´€ê³„ íŒ¨í„´](#-ë„ë©”ì¸ë³„-ê´€ê³„-íŒ¨í„´)

### 4. ê°€ì¤‘ì¹˜ ê³„ì‚°
- [ë¹ˆë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜](#ë¹ˆë„-ê¸°ë°˜-ê°€ì¤‘ì¹˜)
- [ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜](#ì‹ ë¢°ë„-ê¸°ë°˜-ê°€ì¤‘ì¹˜)
- [ê²°í•© ê°€ì¤‘ì¹˜](#ê²°í•©-ê°€ì¤‘ì¹˜)

### 5. êµ¬í˜„ ìƒì„¸
- [ê´€ê³„ ì¶”ì¶œ íŒŒì´í”„ë¼ì¸](#-ê´€ê³„-ì¶”ì¶œ-íŒŒì´í”„ë¼ì¸)
- [ê´€ê³„ ë³‘í•©](#-ê´€ê³„-ë³‘í•©)

### 6. ê³ ê¸‰ ê¸°ë²•
- [ëŒ€ì¹­ ê´€ê³„ ì¶”ë¡ ](#ëŒ€ì¹­-ê´€ê³„-ì¶”ë¡ )
- [ì¶”ë¡ ì  ê´€ê³„](#-ì¶”ë¡ ì -ê´€ê³„)
- [ê·¸ë˜í”„ í†µê³„](#-ê·¸ë˜í”„-í†µê³„)

---

## ğŸ¯ ê´€ê³„ ì¶”ì¶œì˜ ëª©ì 

```mermaid
flowchart LR
    A[ì—”í‹°í‹° ë…¸ë“œë“¤] --> B[ê´€ê³„ ì¶”ì¶œ]
    B --> C[ì—°ê²°ëœ ê·¸ë˜í”„]
    B --> D[ì˜ë¯¸ì  ì—°ê²°]
    B --> E[ê°€ì¤‘ì¹˜ ë¶€ì—¬]
    B --> F[ì¶œì²˜ ì¶”ì ]

    style A fill:#e1f5fe
    style B fill:#fff9c4
    style C fill:#c8e6c9
    style D fill:#e1bee7
    style E fill:#ffccbc
    style F fill:#fff59d
```

1. **ê·¸ë˜í”„ êµ¬ì¡° í˜•ì„±**: ì—”í‹°í‹°ë¥¼ ì—°ê²°í•˜ì—¬ ë„¤íŠ¸ì›Œí¬ ìƒì„±
2. **ì˜ë¯¸ì  ì—°ê²°**: ë‹¨ìˆœ ê³µì±„ë¥¼ ë„˜ì–´ì„  ì˜ë¯¸ ê´€ê³„ íŒŒì•…
3. **ê°€ì¤‘ì¹˜ ê³„ì‚°**: ê´€ê³„ ê°•ë„ ì •ëŸ‰í™”
4. **ì»¨í…ìŠ¤íŠ¸ ì œê³µ**: ì¶”ì  ë° ê²€ì¦ì„ ìœ„í•œ ì¶œì²˜ ì •ë³´

## ğŸ“– ë¹—ëŒ€ì–´ ë³´ê¸°: ì†Œì…œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„

ê´€ê³„ ì¶”ì¶œì€ **ì†Œì…œ ë„¤íŠ¸ì›Œí¬ì—ì„œ ì‚¬ëŒë“¤ ê°„ì˜ ê´€ê³„ë¥¼ ë§¤í•‘í•˜ëŠ” ê²ƒ**ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤:

| ì†Œì…œ ë„¤íŠ¸ì›Œí¬ | ê´€ê³„ ì¶”ì¶œ ì‹œìŠ¤í…œ |
|-------------|----------------|
| ì¹œêµ¬ ê´€ê³„ | entity ê°„ ì—°ê²° |
| ì¹œë°€ë„ ì ìˆ˜ | relationship weight |
| í•¨ê»˜ ìˆëŠ” ì‚¬ì§„ | co-occurrence in text unit |
| ê´€ê³„ íƒ€ì…(ê°€ì¡±, ì§ì¥) | relationship type |
| ì†Œê°œ ê²½ë¡œ | text_unit_ids (ì¶œì²˜) |

```mermaid
flowchart TB
    subgraph Social["ì†Œì…œ ë„¤íŠ¸ì›Œí¬"]
        S1[ğŸ‘¤ Alice] ---|ì¹œêµ¬| S2[ğŸ‘¤ Bob]
        S1 ---|ë™ë£Œ| S3[ğŸ‘¤ Carol]
        S2 ---|ê°€ì¡±| S3
        S1 -.->|S2 ì†Œê°œ| S4[ğŸ‘¤ Dave]
    end

    subgraph GraphRAG["GraphRAG ê´€ê³„"]
        G1[Microsoft] ---|founded| G2[Bill Gates]
        G1 ---|acquired| G3[GitHub]
        G2 ---|partner| G4[Paul Allen]
        G1 -.->|text_unit_123| G5[OpenAI]
    end

    style Social fill:#e3f2fd
    style GraphRAG fill:#f3e5f5
```

## ğŸ—ï¸ ì¶”ì¶œ ì•„í‚¤í…ì²˜

```mermaid
flowchart TB
    subgraph Input["ì…ë ¥"]
        E["Entities<br/>ğŸ“Š ì—”í‹°í‹° ëª©ë¡"]
        TU["Text Units<br/>ğŸ“ í…ìŠ¤íŠ¸ ì²­í¬"]
    </subgraph>

    subgraph Detect["ê´€ê³„ ê°ì§€"]
        CO["ê³µì±„ ë¶„ì„<br/>ğŸ” Co-occurrence<br/>Window-based"]
        LLM["LLM ì¶”ì¶œ<br/>ğŸ¤– ê´€ê³„ ìœ í˜•<br/>ğŸ¤– ì„¤ëª… ìƒì„±"]
        SYM["ëŒ€ì¹­ì„± í™•ì¸<br/>â†”ï¸ Bidirectional?"]
    </subgraph>

    subgraph Weight["ê°€ì¤‘ì¹˜ ê³„ì‚°"]
        FREQ["ë¹ˆë„ ê¸°ë°˜<br/>ğŸ“Š Frequency<br/>ë“±ì¥ íšŸìˆ˜"]
        CONF["ì‹ ë¢°ë„ ì ìˆ˜<br/>ğŸ“ˆ Confidence<br/>LLM ì¶œë ¥ í’ˆì§ˆ"]
        COMB["ê²°í•© ê°€ì¤‘ì¹˜<br/>âš–ï¸ ìµœì¢… ê³„ì‚°"]
    </subgraph>

    subgraph Output["ì¶œë ¥"]
        REL["Relationships<br/>ğŸ“‹ source, target, weight<br/>ğŸ“‹ description<br/>ğŸ“‹ text_unit_ids"]
    </subgraph>

    E --> CO
    E --> LLM
    TU --> LLM

    CO --> FREQ
    LLM --> CONF
    LLM --> SYM

    FREQ --> COMB
    CONF --> COMB
    SYM --> COMB

    COMB --> REL

    style Input fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style Detect fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style Weight fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    style Output fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
```

### ê´€ê³„ ì¶”ì¶œ íë¦„ë„

```mermaid
flowchart TB
    START([ì‹œì‘]) --> GET[í…ìŠ¤íŠ¸ ìœ ë‹›ê³¼<br/>ê´€ë ¨ ì—”í‹°í‹° ê°€ì ¸ì˜¤ê¸°]

    GET --> CHECK{ì—”í‹°í‹° ìˆ˜<br/>â‰¥ 2?}

    CHECK -->|ì•„ë‹ˆì˜¤| SKIP([ê±´ë„ˆë›°ê¸°])
    CHECK -->|ì˜ˆ| COOC[ê³µì±„ ê°ì§€<br/>Window ë¶„ì„]

    COOC --> PAIRS[ì—”í‹°í‹° ìŒ ì¶”ì¶œ]

    PAIRS --> LOOP{ëª¨ë“  ìŒ ì²˜ë¦¬?}

    LOOP -->|ì²˜ë¦¬ ì¤‘| LLM_CALL[LLM ê´€ê³„ ì¶”ì¶œ]

    LLM_CALL --> PARSE[ê²°ê³¼ íŒŒì‹±]

    PARSE --> VALID{ìœ íš¨í•œ ê´€ê³„?}

    VALID -->|ì˜ˆ| ADD[ê´€ê³„ ëª©ë¡ì— ì¶”ê°€]
    VALID -->|ì•„ë‹ˆì˜¤| LOOP

    ADD --> LOOP
    LOOP -->|ì™„ë£Œ| MERGE[ê´€ê³„ ë³‘í•©<br/>ì¤‘ë³µ ì œê±°]

    MERGE --> WEIGHT[ê°€ì¤‘ì¹˜ ê³„ì‚°]

    WEIGHT --> SAVE([ì €ì¥])

    style START fill:#c8e6c9
    style SKIP fill:#ffcdd2
    style SAVE fill:#b39ddb
    style COOC fill:#fff9c4
    style LLM_CALL fill:#e1bee7
```

## ğŸ” ê´€ê³„ ê°ì§€ ë°©ë²•

### 1. ê³µì±„ ê¸°ë°˜ ê°ì§€ (Co-occurrence)

```mermaid
flowchart LR
    A["í…ìŠ¤íŠ¸: Microsoft acquired GitHub<br/>founded by Bill Gates"] --> B[Window ë¶„ì„]

    B --> C[Microsoft]
    B --> D[acquired]
    B --> E[GitHub]
    B --> F[founded]
    B --> G[Bill Gates]

    C --> P1[(M-GitHub)]
    E --> P1
    C --> P2[(M-Bill)]
    G --> P2
    E --> P3[(GitHub-Bill)]
    G --> P3

    style A fill:#e1f5fe
    style P1 fill:#c8e6c9
    style P2 fill:#c8e6c9
    style P3 fill:#fff9c4
```

```python
def detect_cooccurrence(
    text_unit: TextUnit,
    entities: list[Entity],
    window: int = 100  # í† í° ìœˆë„ìš°
) -> list[tuple[str, str, int]]:
    """
    ê°™ì€ ë¬¸ë§¥ì—ì„œ ë“±ì¥í•˜ëŠ” ì—”í‹°í‹° ìŒ ê°ì§€
    """
    entity_positions = {}

    # ì—”í‹°í‹° ìœ„ì¹˜ ë§¤í•‘
    for entity in entities:
        for match in re.finditer(entity.title, text_unit.text):
            entity_positions[entity.id] = match.start()

    # ê°€ê¹Œìš´ ì—”í‹°í‹° ìŒ ì°¾ê¸°
    relationships = []
    for e1, pos1 in entity_positions.items():
        for e2, pos2 in entity_positions.items():
            if e1 < e2 and abs(pos1 - pos2) <= window:
                relationships.append((e1, e2))

    return relationships
```

### 2. LLM ê¸°ë°˜ ê´€ê³„ ì¶”ì¶œ

```
From the text below, extract relationships between entities.

For each relationship, provide:
- source: Source entity
- target: Target entity
- description: How they relate
- weight: Strength (0-1)

Entities in context:
{entity_list}

Text: {text}

Output format:
Source: {entity}
Target: {entity}
Description: {relationship}
Weight: {float}
```

### ê´€ê³„ ê°ì§€ ë°©ë²• ë¹„êµ

```mermaid
flowchart TB
    subgraph Methods["ê°ì§€ ë°©ë²• ë¹„êµ"]
        direction TB
        CO["Co-occurrence<br/>âš¡ ë¹ ë¦„<br/>ğŸ“Š ë†’ì€ ì¬í˜„ìœ¨<br/>âŒ ë‚®ì€ ì •í™•ë„"]
        LL["LLM ê¸°ë°˜<br/>ğŸŒ ëŠë¦¼<br/>ğŸ¯ ë†’ì€ ì •í™•ë„<br/>âœ… ì˜ë¯¸ ì´í•´"]
        HY["í•˜ì´ë¸Œë¦¬ë“œ<br/>âš–ï¸ ê· í˜•<br/>ğŸ”„ ë‘ ë°©ë²• ê²°í•©"]
    end

    CO --> HY
    LL --> HY

    style CO fill:#fff9c4
    style LL fill:#e1bee7
    style HY fill:#c8e6c9
```

## ğŸ“‹ ê´€ê³„ ìœ í˜• ë¶„ë¥˜

### ê¸°ë³¸ ê´€ê³„ ìœ í˜•

```mermaid
mindmap
    root((ê´€ê³„ ìœ í˜•))
        Organizational
            founded_by
            acquired
            subsidiary
            partner
            competitor
        Personal
            married_to
            parent_of
            colleague
            friend
            mentor
        Locational
            located_in
            operates_in
            based_in
            headquarters_in
        Temporal
            preceded_by
            succeeded_by
            concurrent_with
        Functional
            uses
            produces
            depends_on
            integrates_with
        Semantic
            related_to
            similar_to
            example_of
            part_of
```

| ìœ í˜• | íŒ¨í„´ | ì˜ˆì‹œ | ë°©í–¥ì„± |
|------|------|------|--------|
| **Organizational** | ì¡°ì§ êµ¬ì¡° | Microsoft â†’ acquired â†’ GitHub | ë‹¨ë°©í–¥ |
| **Personal** | ì‚¬ëŒ ê´€ê³„ | Satya â†’ CEO_of â†’ Microsoft | ë‹¨ë°©í–¥ |
| **Locational** | ìœ„ì¹˜ ê¸°ë°˜ | GitHub â†’ based_in â†’ San Francisco | ë‹¨ë°©í–¥ |
| **Temporal** | ì‹œê°„ ê¸°ë°˜ | GPT-3 â†’ preceded_by â†’ GPT-4 | ë‹¨ë°©í–¥ |
| **Functional** | ê¸°ëŠ¥ì  | Azure â†’ uses â†’ OpenAI | ë‹¨ë°©í–¥ |

### ë„ë©”ì¸ë³„ ê´€ê³„ íŒ¨í„´

```mermaid
flowchart TB
    subgraph Tech["ê¸°ìˆ  ë„ë©”ì¸"]
        T1[uses API]
        T2[integrates]
        T3[depends_on]
        T4[forks]
        T5[contributes_to]
    end

    subgraph Business["ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸"]
        B1[acquired]
        B2[invested_in]
        B3[partner]
        B4[competitor]
        B5[customer_of]
    end

    subgraph Research["ì—°êµ¬ ë„ë©”ì¸"]
        R1[cited_by]
        R2[builds_on]
        R3[collaborator]
        R4[affiliated_with]
        R5[reviewed]
    end

    style Tech fill:#e3f2fd
    style Business fill:#fff9c4
    style Research fill:#f8bbd9
```

## ğŸ“Š ê°€ì¤‘ì¹˜ ê³„ì‚°

### ê°€ì¤‘ì¹˜ êµ¬ì„± ìš”ì†Œ

```mermaid
flowchart LR
    A[ê´€ê³„ ê°€ì¤‘ì¹˜] --> B[ë¹ˆë„ ê¸°ë°˜<br/>Frequency 70%]
    A --> C[ì‹ ë¢°ë„ ê¸°ë°˜<br/>Confidence 30%]

    B --> B1["ë“±ì¥ íšŸìˆ˜<br/>í…ìŠ¤íŠ¸ ìœ ë‹› ìˆ˜"]
    C --> C1["LLM ì¶œë ¥ í’ˆì§ˆ<br/>ì„¤ëª… ê¸¸ì´"]

    style A fill:#fff9c4
    style B fill:#c8e6c9
    style C fill:#e1bee7
```

### ë¹ˆë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜

```python
def calculate_frequency_weight(
    relationships: list[Relationship],
    text_units: list[TextUnit]
) -> dict[str, float]:
    """
    ê´€ê³„ ë“±ì¥ ë¹ˆë„ë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚°
    """
    freq = defaultdict(int)

    for rel in relationships:
        for unit_id in rel.text_unit_ids:
            # ê´€ê³„ IDë¡œ ë¹ˆë„ ì¹´ìš´íŠ¸
            freq[rel.id] += 1

    # ì •ê·œí™”
    max_freq = max(freq.values()) if freq else 1
    weights = {k: v/max_freq for k, v in freq.items()}

    return weights
```

### ê°€ì¤‘ì¹˜ ë¶„í¬ ì˜ˆì‹œ

```mermaid
flowchart TB
    subgraph Weight["ê°€ì¤‘ì¹˜ ë²”ìœ„ë³„ ì˜ë¯¸"]
        W1["0.9 - 1.0<br/>ë§¤ìš° ê°•í•œ ê´€ê³„<br/>ì—¬ëŸ¬ ì¶œì²˜ì—ì„œ í™•ì¸"]
        W2["0.7 - 0.9<br/>ê°•í•œ ê´€ê³„<br/>ëª…í™•í•œ ì—°ê²°"]
        W3["0.4 - 0.7<br/>ì¤‘ê°„ ê´€ê³„<br/>ì¼ë°˜ì  ì—°ê²°"]
        W4["0.1 - 0.4<br/>ì•½í•œ ê´€ê³„<br/>ê°„ì ‘ì  ì—°ê²°"]
        W5["0.0 - 0.1<br/>ë§¤ìš° ì•½í•¨<br/>ê±°ì˜ ì—°ê²° ì—†ìŒ"]
    end

    style W1 fill:#c8e6c9
    style W2 fill:#a5d6a7
    style W3 fill:#fff59d
    style W4 fill:#ffccbc
    style W5 fill:#ffcdd2
```

### ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜

```python
def calculate_confidence_weight(
    llm_response: str,
    entity_similarity: float
) -> float:
    """
    LLM ì‘ë‹µ ì‹ ë¢°ë„ ê³„ì‚°
    """
    # 1. êµ¬ì¡°ì  ì™„ì „ì„±
    has_all_fields = check_completeness(llm_response)

    # 2. ì—”í‹°í‹° ê´€ë ¨ì„±
    relevance = entity_similarity

    # 3. ì„¤ëª… í’ˆì§ˆ
    description_quality = len(llm_response.split()) / 10  # ë‹¨ì–´ ìˆ˜ ê¸°ë°˜

    # ì¢…í•© ì‹ ë¢°ë„
    confidence = (
        has_all_fields * 0.4 +
        relevance * 0.3 +
        min(description_quality, 1.0) * 0.3
    )

    return confidence
```

### ê²°í•© ê°€ì¤‘ì¹˜

```python
weight = frequency * 0.7 + confidence * 0.3
```

## ğŸ”§ êµ¬í˜„ ìƒì„¸

### ê´€ê³„ ì¶”ì¶œ íŒŒì´í”„ë¼ì¸

```mermaid
flowchart TB
    START([í…ìŠ¤íŠ¸ ìœ ë‹›]) --> FILTER[ê´€ë ¨ ì—”í‹°í‹° í•„í„°ë§]

    FILTER --> CHECK{ì—”í‹°í‹° â‰¥ 2?}

    CHECK -->|ì•„ë‹ˆì˜¤| NEXT([ë‹¤ìŒ ìœ ë‹›])
    CHECK -->|ì˜ˆ| COOC[ê³µì±„ ê°ì§€]

    COOC --> PAIRS[ì—”í‹°í‹° ìŒ ëª©ë¡]

    PAIRS --> PAIR_LOOP{ê° ìŒ ì²˜ë¦¬}

    PAIR_LOOP -->|ì²˜ë¦¬ ì¤‘| LLM_EXT[LLM ê´€ê³„ ì¶”ì¶œ]

    LLM_EXT --> PARSE[ê²°ê³¼ íŒŒì‹±]

    PARSE --> CREATE[Relationship ê°ì²´ ìƒì„±]

    CREATE --> PAIR_LOOP

    PAIR_LOOP -->|ì™„ë£Œ| MERGE[ê´€ê³„ ë³‘í•©<br/>ì¤‘ë³µ ì œê±°]

    MERGE --> WEIGHT[ê°€ì¤‘ì¹˜ ì¬ê³„ì‚°]

    WEIGHT --> SAVE([ì €ì¥])

    style START fill:#e1f5fe
    style NEXT fill:#ffcdd2
    style SAVE fill:#c8e6c9
    style LLM_EXT fill:#e1bee7
```

```python
async def extract_relationships(
    text_units: pd.DataFrame,
    entities: pd.DataFrame,
    llm: BaseLanguageModel,
) -> pd.DataFrame:
    """
    í…ìŠ¤íŠ¸ ìœ ë‹›ì—ì„œ ê´€ê³„ ì¶”ì¶œ
    """
    relationships = []

    # ê° í…ìŠ¤íŠ¸ ìœ ë‹›ì— ëŒ€í•´
    for _, unit in text_units.iterrows():
        # í•´ë‹¹ ìœ ë‹›ì˜ ì—”í‹°í‹° í•„í„°ë§
        unit_entities = entities[
            entities['text_unit_ids'].apply(
                lambda x: unit['id'] in str(x)
            )
        ]

        if len(unit_entities) < 2:
            continue

        # ê³µì±„ ê°ì§€
        cooccur = detect_cooccurrence(unit, unit_entities)

        # LLM ê¸°ë°˜ ê´€ê³„ ì¶”ì¶œ
        for e1_id, e2_id in cooccur:
            e1 = unit_entities[unit_entities['id'] == e1_id].iloc[0]
            e2 = unit_entities[unit_entities['id'] == e2_id].iloc[0]

            # LLM í˜¸ì¶œ
            result = await llm.extract_relationship(
                text=unit['text'],
                entity1=e1['title'],
                entity2=e2['title']
            )

            # ê´€ê³„ ìƒì„±
            rel = Relationship(
                source=e1_id,
                target=e2_id,
                description=result['description'],
                weight=result['weight'],
                text_unit_ids=[unit['id']]
            )
            relationships.append(rel)

    # ì¤‘ë³µ ì œê±° ë° ê°€ì¤‘ì¹˜ ë³‘í•©
    relationships = merge_relationships(relationships)

    return pd.DataFrame([r.to_dict() for r in relationships])
```

### ê´€ê³„ ë³‘í•© ì•Œê³ ë¦¬ì¦˜

```mermaid
flowchart TB
    A[ê´€ê³„ ëª©ë¡] --> B[Source-Targetë³„<br/>ê·¸ë£¹í™”]

    B --> C{ê·¸ë£¹ í¬ê¸° > 1?}

    C -->|ì˜ˆ| D[ê°€ì¤‘ì¹˜ í‰ê· ]
    C -->|ì•„ë‹ˆì˜¤| E[ë‹¨ì¼ ê´€ê³„ ìœ ì§€]

    D --> F[í…ìŠ¤íŠ¸ ìœ ë‹› ë³‘í•©]
    E --> F

    F --> G[ìµœìƒìœ„ ì„¤ëª… ì„ íƒ]

    G --> H[ë³‘í•©ëœ ê´€ê³„]

    style A fill:#e1f5fe
    style H fill:#c8e6c9
    style D fill:#fff9c4
    style G fill:#e1bee7
```

```python
def merge_relationships(
    relationships: list[Relationship]
) -> list[Relationship]:
    """
    ë™ì¼í•œ source-target ìŒì˜ ê´€ê³„ ë³‘í•©
    """
    groups = defaultdict(list)

    # ê·¸ë£¹í•‘
    for rel in relationships:
        key = (rel.source, rel.target)
        groups[key].append(rel)

    # ë³‘í•©
    merged = []
    for key, rels in groups.items():
        # ê°€ì¤‘ì¹˜ í‰ê· 
        avg_weight = sum(r.weight for r in rels) / len(rels)

        # í…ìŠ¤íŠ¸ ìœ ë‹› í•©ì¹˜ê¸°
        all_units = []
        for r in rels:
            all_units.extend(r.text_unit_ids or [])

        # ì„¤ëª… ë³‘í•© (ê°€ì¥ ìì„¸í•œ ê²ƒ ì„ íƒ)
        best_desc = max(rels, key=lambda r: len(r.description or ""))

        merged.append(Relationship(
            source=key[0],
            target=key[1],
            weight=avg_weight,
            description=best_desc.description,
            text_unit_ids=list(set(all_units))
        ))

    return merged
```

## ğŸ“ˆ ê´€ê³„ í†µê³„

### ì¼ë°˜ì ì¸ ë¶„í¬

```mermaid
flowchart TB
    subgraph Stats["ê·¸ë˜í”„ í†µê³„"]
        S1["í‰ê·  ê´€ê³„ìˆ˜/ì—”í‹°í‹°<br/>3-10ê°œ"]
        S2["ìµœëŒ€ ê´€ê³„ìˆ˜/ì—”í‹°í‹°<br/>50-100ê°œ"]
        S3["í‰ê·  ê°€ì¤‘ì¹˜<br/>0.3-0.7"]
        S4["ë‹¨ë°©í–¥ ê´€ê³„ ë¹„ìœ¨<br/>70-90%"]
    end

    S1 --> C1["í—ˆë¸Œ ì—”í‹°í‹°: ë§ì€ ì—°ê²°"]
    S2 --> C2["ì¤‘ìš” ì—”í‹°í‹°: ì¤‘ì‹¬ ì—­í• "]
    S3 --> C3["ê°•í•œ ì—°ê²°: ì£¼ìš” ê´€ê³„"]
    S4 --> C4["ë¹„ëŒ€ì¹­: ë°©í–¥ì„± ì¡´ì¬"]

    style Stats fill:#e3f2fd
    style C1 fill:#c8e6c9
    style C2 fill:#fff9c4
    style C3 fill:#e1bee7
    style C4 fill:#ffccbc
```

| ë©”íŠ¸ë¦­ | ì¼ë°˜ì  ê°’ | ì˜ë¯¸ |
|--------|-----------|------|
| í‰ê·  ê´€ê³„ìˆ˜/ì—”í‹°í‹° | 3-10 | ëŒ€ë¶€ë¶„ ì—”í‹°í‹°ëŠ” ì†Œìˆ˜ì˜ ì—°ê²° |
| ìµœëŒ€ ê´€ê³„ìˆ˜/ì—”í‹°í‹° | 50-100 | í—ˆë¸Œ ì—”í‹°í‹° ì¡´ì¬ |
| í‰ê·  ê°€ì¤‘ì¹˜ | 0.3-0.7 | ì¤‘ê°„ ì •ë„ ê°•ë„ |
| ë‹¨ë°©í–¥ ê´€ê³„ ë¹„ìœ¨ | 70-90% | ëŒ€ë¶€ë¶„ ë¹„ëŒ€ì¹­ ê´€ê³„ |

### ê·¸ë˜í”„ ì§€í‘œ

```python
# ê·¸ë˜í”„ ë¶„ì„
import networkx as nx

G = nx.Graph()
for rel in relationships:
    G.add_edge(rel.source, rel.target, weight=rel.weight)

# ë„¤íŠ¸ì›Œí¬ ì§€í‘œ
avg_degree = sum(dict(G.degree()).values()) / len(G.nodes())
density = nx.density(G)
clustering = nx.average_clustering(G)

print(f"Avg Degree: {avg_degree:.2f}")
print(f"Density: {density:.4f}")
print(f"Clustering: {clustering:.4f}")
```

## ğŸ“ ê³ ê¸‰ ê¸°ë²•

### 1. ëŒ€ì¹­ ê´€ê³„ ì¶”ë¡ 

```mermaid
flowchart TB
    A[A â†’ B ê´€ê³„ ë°œê²¬] --> B{ëŒ€ì¹­ì <br/>ê´€ê³„ ìœ í˜•?}

    B -->|ì˜ˆ| C{ì—­ë°©í–¥<br/>ì¡´ì¬?}

    B -->|ì•„ë‹ˆì˜¤| D[ë‹¨ë°©í–¥ ìœ ì§€]

    C -->|ì•„ë‹ˆì˜¤| E[B â†’ A ê´€ê³„ ìƒì„±]

    C -->|ì˜ˆ| D

    E --> F[ì–‘ë°©í–¥ ê´€ê³„]

    style A fill:#e1f5fe
    style E fill:#c8e6c9
    style F fill:#e1bee7
```

```python
def infer_symmetric_relationships(
    relationships: list[Relationship]
) -> list[Relationship]:
    """
    A -> B ê´€ê³„ì—ì„œ B -> A ê´€ê³„ ì¶”ë¡ 
    """
    symmetric_types = {
        'colleague_of', 'partner_of',
        'connected_to', 'related_to'
    }

    new_relations = []
    for rel in relationships:
        # ëŒ€ì¹­ì  ê´€ê³„ ìœ í˜•ì¸ì§€ í™•ì¸
        if any(t in rel.description.lower() for t in symmetric_types):
            # ì—­ë°©í–¥ ê´€ê³„ í™•ì¸
            has_reverse = any(
                r.source == rel.target and r.target == rel.source
                for r in relationships
            )
            if not has_reverse:
                # ì—­ë°©í–¥ ê´€ê³„ ìƒì„±
                new_relations.append(Relationship(
                    source=rel.target,
                    target=rel.source,
                    description=rel.description,
                    weight=rel.weight
                ))

    return relationships + new_relations
```

### 2. ì¶”ë¡ ì  ê´€ê³„

```mermaid
flowgraph TB
    A[ì—”í‹°í‹° A] -->|ê´€ê³„| B[ì—”í‹°í‹° B]
    B -->|ê´€ê³„| C[ì—”í‹°í‹° C]

    A -.->|ì¶”ë¡ | C[ê°„ì ‘ ê´€ê³„]

    style A fill:#c8e6c9
    style B fill:#fff9c4
    style C fill:#e1bee7
```

```python
def infer_transitive_relationships(
    G: nx.Graph,
    min_path_length: int = 2
) -> list[tuple[str, str, str]]:
    """
    ì¶”ì´ì  ê´€ê³„ ì¶”ë¡ 
    A -> B -> Cì—ì„œ A -> C ê´€ê³„ ì¶”ë¡ 
    """
    inferred = []

    for node1 in G.nodes():
        for node2 in G.nodes():
            if node1 == node2:
                continue

            # 2-hop ê²½ë¡œ ì°¾ê¸°
            try:
                path = nx.shortest_path(G, node1, node2)
                if len(path) == 3:  # 2-hop
                    inferred.append((node1, node2, "indirect"))
            except nx.NetworkXNoPath:
                continue

    return inferred
```

### 3. ê´€ê³„ ê°•í™” ì „ëµ

```mermaid
flowchart TB
    subgraph "ê´€ê³„ ê°•í™” ë°©ë²•"
        DIR["ì§ì ‘ ê°•í™”<br/>ë” ë§ì€ ì¶œì²˜ ìˆ˜ì§‘"]
        IND["ê°„ì ‘ ê°•í™”<br/>ì¶”ë¡ ì  ê´€ê³„ ì¶”ê°€"]
        SYM["ëŒ€ì¹­í™”<br/>ì–‘ë°©í–¥ ê´€ê³„ ìƒì„±"]
        TRU["ì‹ ë¢°ë„ í•„í„°ë§<br/>ë‚®ì€ ê°€ì¤‘ì¹˜ ì œê±°"]
    end

    style DIR fill:#c8e6c9
    style IND fill:#fff9c4
    style SYM fill:#e1bee7
    style TRU fill:#ffccbc
```

## ğŸ”— ê´€ë ¨ ì»´í¬ë„ŒíŠ¸

- [[Entity Extraction Deep Dive]]: ì—”í‹°í‹° ì¶”ì¶œ
- [[Entity]]: ì—”í‹°í‹° ë°ì´í„° ëª¨ë¸
- [[Community]]: ê´€ê³„ë¥¼ í†µí•œ ì»¤ë®¤ë‹ˆí‹° í˜•ì„±
- [[Leiden Algorithm]]: ì»¤ë®¤ë‹ˆí‹° ê°ì§€

## ğŸ’¡ ì„±ëŠ¥ ìµœì í™” íŒ

1. **ì‚¬ì „ í•„í„°ë§**: ì¤‘ìš”í•œ ì—”í‹°í‹° ìŒë§Œ ì¶”ì¶œ
2. **ë°°ì¹˜ LLM í˜¸ì¶œ**: ì—¬ëŸ¬ ê´€ê³„ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
3. **ìºì‹±**: ë™ì¼ ì—”í‹°í‹° ìŒ ì¬ì²˜ë¦¬ ë°©ì§€
4. **ë³‘ë ¬ ì²˜ë¦¬**: ë…ë¦½ì ì¸ í…ìŠ¤íŠ¸ ìœ ë‹› ë³‘ë ¬ ì²˜ë¦¬

---
*See also: [[Relationship]], [[Entity]], [[Index Module]]*
