---
title: ì¸ë±ì‹± API
tags:
  - api
  - indexing
  - python-api
created: 2025-01-12
type: api-reference
links:
  - [[Query API]]
  - [[Indexing API]]
  - [[Indexing API]]
  - [[Index Module]]
---

# ì¸ë±ì‹± API

**ì¸ë±ì‹± API**ëŠ” ì†ŒìŠ¤ ë¬¸ì„œì—ì„œ ì§€ì‹ ê·¸ë˜í”„ ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•œ í”„ë¡œê·¸ë˜ë§¤í‹± ì•¡ì„¸ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“‹ ê°œìš”

```python
from graphrag.api import build_index

await build_index(config_or_path)
```

## ğŸ”§ í•¨ìˆ˜ ë ˆí¼ëŸ°ìŠ¤

### build_index()

ì†ŒìŠ¤ ë¬¸ì„œì—ì„œ ì§€ì‹ ê·¸ë˜í”„ ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.

```python
async def build_index(
    config: GraphRagConfig | str,
    callbacks: WorkflowCallbacks | None = None,
    is_update_run: bool = False,
    memory_profile: bool = False,
) -> None:
    """
    ì§€ì‹ ê·¸ë˜í”„ ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.

    Args:
        config: ì„¤ì • ê°ì²´ ë˜ëŠ” settings.yaml ê²½ë¡œ
        callbacks: ì§„í–‰ë¥  ì¶”ì ì„ ìœ„í•œ ì„ íƒì  ì½œë°±
        is_update_run: Trueì¸ ê²½ìš° ì¦ë¶„ ì—…ë°ì´íŠ¸ ì‹¤í–‰
        memory_profile: ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ í™œì„±í™”

    Raises:
        GraphRAGError: íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ ì‹œ
    """
```

## ğŸ“ ì‚¬ìš© ì˜ˆì œ

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from graphrag.api import build_index

# ì„¤ì • íŒŒì¼ ê²½ë¡œ ì‚¬ìš©
await build_index("./settings.yaml")

# ì„¤ì • ê°ì²´ ì‚¬ìš©
from graphrag.config import load_config
config = load_config("./project")
await build_index(config)
```

### ì½œë°±ê³¼ í•¨ê»˜ ì‚¬ìš©

```python
from graphrag.api import build_index
from graphrag.callbacks import WorkflowCallbacks

class MyCallbacks(WorkflowCallbacks):
    def on_workflow_start(self, name: str):
        print(f"Starting: {name}")

    def on_workflow_end(self, name: str, result):
        print(f"Finished: {name}")

    def on_llm_start(self, text: str):
        print(f"LLM call: {text[:50]}...")

    def on_llm_end(self, text: str, response: str):
        print(f"LLM response: {len(response)} tokens")

await build_index(
    "./settings.yaml",
    callbacks=MyCallbacks()
)
```

### ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ê³¼ í•¨ê»˜ ì‚¬ìš©

```python
from graphrag.api import build_index

await build_index(
    "./settings.yaml",
    memory_profile=True
)
# ë©”ëª¨ë¦¬ ì‚¬ìš© í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤
```

### ì¦ë¶„ ì—…ë°ì´íŠ¸

```python
from graphrag.api import build_index

await build_index(
    "./settings.yaml",
    is_update_run=True
)
```

## âš™ï¸ ì„¤ì •

### ìµœì†Œ ì„¤ì •

```yaml
# settings.yaml
models:
  default_chat_model:
    type: openai_chat
    model: gpt-4-turbo-preview
    api_key: ${OPENAI_API_KEY}

  default_embedding_model:
    type: openai_embedding
    model: text-embedding-3-small
    api_key: ${OPENAI_API_KEY}

input:
  type: file
  file_type: text
  file_pattern: "input/*.txt"

output:
  type: file
  base_dir: "./output"

chunks:
  size: 1200
  overlap: 100

vector_store:
  type: lancedb
  db_uri: "./output/lancedb"
```

### ì „ì²´ ì„¤ì •

ëª¨ë“  ì˜µì…˜ì€ [[Configuration Module]]ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ“Š ì¶œë ¥

### ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
output/
â”œâ”€â”€ create_final_documents.parquet
â”œâ”€â”€ create_final_text_units.parquet
â”œâ”€â”€ create_final_entities.parquet
â”œâ”€â”€ create_final_relationships.parquet
â”œâ”€â”€ create_final_communities.parquet
â”œâ”€â”€ create_final_community_reports.parquet
â”œâ”€â”€ create_final_covariates.parquet
â””â”€â”€ lancedb/
```

### ê²°ê³¼ ì½ê¸°

```python
import pandas as pd

# ì—”í‹°í‹° ë¡œë“œ
entities = pd.read_parquet("output/create_final_entities.parquet")
print(f"Extracted {len(entities)} entities")

# ì»¤ë®¤ë‹ˆí‹° ë¡œë“œ
communities = pd.read_parquet("output/create_final_communities.parquet")
print(f"Found {len(communities)} communities")

# ë¦¬í¬íŠ¸ ë¡œë“œ
reports = pd.read_parquet("output/create_final_community_reports.parquet")
for _, report in reports.iterrows():
    print(f"{report['community']}: {report['summary']}")
```

## ğŸ› ì˜¤ë¥˜ ì²˜ë¦¬

```python
from graphrag.api import build_index
from graphrag.errors import (
    GraphRAGError,
    ConfigurationError,
    LLMError,
    StorageError
)

try:
    await build_index("./settings.yaml")
except ConfigurationError as e:
    print(f"Configuration error: {e}")
except LLMError as e:
    print(f"LLM error: {e}")
except StorageError as e:
    print(f"Storage error: {e}")
except GraphRAGError as e:
    print(f"General error: {e}")
```

## âš¡ ì„±ëŠ¥ íŒ

1. **ìºì‹± í™œì„±í™”**: LLM API í˜¸ì¶œ ê°ì†Œ
   ```yaml
   cache:
     type: file
     base_dir: "./cache"
   ```

2. **ë¹ ë¥¸ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©**: ë” ë¹ ë¥¸ ì²˜ë¦¬
   ```bash
   graphrag index --method fast
   ```

3. **ë™ì‹œì„± ì¡°ì •**: API ì œí•œì— ë§ì¶”ê¸°
   ```yaml
   models:
     default_chat_model:
       concurrent_requests: 25
       requests_per_minute: 500
   ```

## ğŸ”— ê´€ë ¨ ì£¼ì œ

- [[Query API]] - ì¸ë±ìŠ¤ ê²€ìƒ‰
- [[Indexing API]] - í”„ë¡œì íŠ¸ ì„¤ì •
- [[Indexing API]] - ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸
- [[Configuration Module]] - ëª¨ë“  ì˜µì…˜
- [[Index Module]] - ì¸ë±ì‹± ì‘ë™ ë°©ì‹

---
*ì°¸ê³ : [[Indexing API]], [[Query API]], [[Index Module]]*
