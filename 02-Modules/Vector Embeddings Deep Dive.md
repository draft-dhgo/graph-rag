---
title: Vector Embeddings Deep Dive
tags:
  - deep-dive
  - embeddings
  - vectors
  - semantic-search
  - nlp
created: 2025-01-12
type: deep-dive
links:
  - [[Storage Module]]
  - [[Local Search]]
  - [[Text Unit]]
  - [[Entity]]
---

# Vector Embeddings Deep Dive

ë²¡í„° ì„ë² ë”©(Vector Embeddings)ì€ í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ìˆ˜ì¹˜ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬, ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ê³„ì‚°ê³¼ ì‹œë§¨í‹± ì„œì¹˜ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤.

## ëª©ì°¨

### 1. ê°œìš”
- [ì„ë² ë”©ì˜ ëª©ì ](#-ì„ë² ë”©ì˜-ëª©ì )
- [ë¹—ëŒ€ì–´ ë³´ê¸°: ë„ì„œê´€ ìœ„ì¹˜ ì‹œìŠ¤í…œ](#-ë¹—ëŒ€ì–´-ë³´ê¸°-ë„ì„œê´€-ìœ„ì¹˜-ì‹œìŠ¤í…œ)

### 2. ì•„í‚¤í…ì²˜
- [ì„ë² ë”© ì•„í‚¤í…ì²˜](#-ì„ë² ë”©-ì•„í‚¤í…ì²˜)
- [ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸](#-ì²˜ë¦¬-íŒŒì´í”„ë¼ì¸)

### 3. ì„ë² ë”© ëª¨ë¸
- [OpenAI Embeddings](#openai-embeddings)
- [ì°¨ì› ì„ íƒ ê°€ì´ë“œ](#-ì°¨ì›-ì„ íƒ-ê°€ì´ë“œ)

### 4. ì„ë² ë”© ì „ëµ
- [í…ìŠ¤íŠ¸ ì²­í¬ ì„ë² ë”©](#1-í…ìŠ¤íŠ¸-ì²­í¬-ì„ë² ë”©)
- [ì—”í‹°í‹° ì„¤ëª… ì„ë² ë”©](#2-ì—”í‹°í‹°-ì„¤ëª…-ì„ë² ë”©)
- [ì»¤ë®¤ë‹ˆí‹° ì»¨í…ìŠ¤íŠ¸ ì„ë² ë”©](#3-ì»¤ë®¤ë‹ˆí‹°-ì»¨í…ìŠ¤íŠ¸-ì„ë² ë”©)

### 5. ìœ ì‚¬ë„ ê³„ì‚°
- [ì½”ì‚¬ì¸ ìœ ì‚¬ë„](#ì½”ì‚¬ì¸-ìœ ì‚¬ë„-cosine-similarity)
- [ë‹¤ë¥¸ ìœ ì‚¬ë„ ë©”íŠ¸ë¦­](#ë‹¤ë¥¸-ìœ ì‚¬ë„-ë©”íŠ¸ë¦­)

### 6. ê²€ìƒ‰ ê¸°ë²•
- [Top-K ê²€ìƒ‰](#top-k-ê²€ìƒ‰)
- [ANN ê²€ìƒ‰](#ann-approximate-nearest-neighbor)
- [í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰](#í•˜ì´ë¸Œë¦¬ë“œ-ê²€ìƒ‰)

### 7. ìµœì í™”
- [ì„ë² ë”© ìµœì í™”](#-ì„ë² ë”©-ìµœì í™”)

---

## ğŸ¯ ì„ë² ë”©ì˜ ëª©ì 

```mermaid
flowchart LR
    A[í…ìŠ¤íŠ¸] --> B[ì„ë² ë”©]
    B --> C[ì˜ë¯¸ë¡ ì  ê²€ìƒ‰]
    B --> D[ìœ ì‚¬ë„ ê³„ì‚°]
    B --> E[í´ëŸ¬ìŠ¤í„°ë§]
    B --> F[ì¶”ì²œ]

    style A fill:#e1f5fe
    style B fill:#fff9c4
    style C fill:#c8e6c9
    style D fill:#e1bee7
    style E fill:#ffccbc
    style F fill:#fff59d
```

1. **ì˜ë¯¸ë¡ ì  ê²€ìƒ‰**: í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë„˜ì–´ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰
2. **ìœ ì‚¬ë„ ê³„ì‚°**: í…ìŠ¤íŠ¸/ì—”í‹°í‹° ê°„ ì˜ë¯¸ì  ê±°ë¦¬ ì¸¡ì •
3. **í´ëŸ¬ìŠ¤í„°ë§**: ìœ ì‚¬í•œ í•­ëª©ë“¤ì˜ ê·¸ë£¹í™”
4. **ì¶”ì²œ**: ê´€ë ¨ ì½˜í…ì¸ ì˜ ì¶”ì²œ

## ğŸ“– ë¹—ëŒ€ì–´ ë³´ê¸°: ë„ì„œê´€ ìœ„ì¹˜ ì‹œìŠ¤í…œ

ë²¡í„° ì„ë² ë”©ì€ **ë„ì„œê´€ì—ì„œ ì±…ì˜ ì£¼ì œë³„ ìœ„ì¹˜ë¥¼ ì¢Œí‘œë¡œ ë‚˜íƒ€ë‚´ëŠ” ê²ƒ**ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤:

| ë„ì„œê´€ ì‹œìŠ¤í…œ | ë²¡í„° ì„ë² ë”© |
|-------------|------------|
| ì±… ì£¼ì œ ë¶„ë¥˜ | í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜ |
| ë¹„ìŠ·í•œ ì£¼ì œ ê·¼ì²˜ ë°°ì¹˜ | ìœ ì‚¬í•œ ì˜ë¯¸ ê°€ê¹Œìš´ ì¢Œí‘œ |
| ì£¼ì œ ê±°ë¦¬ ê³„ì‚° | ì½”ì‚¬ì¸ ìœ ì‚¬ë„ |
| ìƒˆ ì±… ìœ„ì¹˜ ë°°ì • | ìƒˆ í…ìŠ¤íŠ¸ ì„ë² ë”© |
| ë¶„ì•¼ë³„ ì„¹ì…˜ | í´ëŸ¬ìŠ¤í„°ë§ |

```mermaid
flowchart TB
    subgraph Library["ë„ì„œê´€ ë¶„ë¥˜"]
        L1["ğŸ“š ì»´í“¨í„° ê³¼í•™<br/>Q1-100"]
        L2["ğŸ“š ì¸ê³µì§€ëŠ¥<br/>Q1-110"]
        L3["ğŸ“š ê¸°ê³„í•™ìŠµ<br/>Q1-115"]
        L4["ğŸ“š ë”¥ëŸ¬ë‹<br/>Q1-118"]
    end

    subgraph Embedding["ë²¡í„° ê³µê°„"]
        E1["[0.8, 0.3, 0.9]<br/>Computer Science"]
        E2["[0.9, 0.4, 0.8]<br/>AI"]
        E3["[0.95, 0.5, 0.85]<br/>Machine Learning"]
        E4["[0.98, 0.6, 0.88]<br/>Deep Learning"]
    end

    style Library fill:#e3f2fd
    style Embedding fill:#f3e5f5
```

### ë²¡í„° ê³µê°„ ì‹œê°í™”

```mermaid
flowchart LR
    subgraph "2D ë²¡í„° ê³µê°„ (ì¶•ì•½ ì˜ˆì‹œ)"
        direction TB

        A["ğŸ¤– AI<br/>(0.8, 0.9)"]
        B["ğŸ§  ML<br/>(0.85, 0.88)"]
        C["ğŸ”® DL<br/>(0.9, 0.85)"]

        D["ğŸ“Š ë°ì´í„°<br/>(0.3, 0.4)"]
        E["ğŸ“ˆ í†µê³„<br/>(0.35, 0.38)"]

        F["ğŸŒ ì›¹<br/>(0.1, 0.2)"]
        G["ğŸ¨ ë””ìì¸<br/>(0.05, 0.15)"]
    end

    style A fill:#c8e6c9
    style B fill:#c8e6c9
    style C fill:#c8e6c9
    style D fill:#fff9c4
    style E fill:#fff9c4
    style F fill:#ffcdd2
    style G fill:#ffcdd2
```

## ğŸ—ï¸ ì„ë² ë”© ì•„í‚¤í…ì²˜

```mermaid
flowchart TB
    subgraph Input["ì…ë ¥ ë°ì´í„°"]
        T["ğŸ“ Text<br/>ë¬¸ì„œ ì²­í¬"]
        E["ğŸ·ï¸ Entity<br/>ì—”í‹°í‹° ì„¤ëª…"]
        C["ğŸŒ Community<br/>ì»¤ë®¤ë‹ˆí‹° ìš”ì•½"]
    end

    subgraph Encode["ì¸ì½”ë”© ë‹¨ê³„"]
        TOKEN["ğŸ”¤ í† í°í™”<br/>tiktoken<br/>ë¬¸ì â†’ í† í° ID"]
        EMBED["ğŸ”„ ì„ë² ë”© ëª¨ë¸<br/>OpenAI/Cohere<br/>í† í° â†’ ë²¡í„°"]
        NORM["âš–ï¸ ì •ê·œí™”<br/>L2 Normalization<br/>ë‹¨ìœ„ ë²¡í„°"]
    end

    subgraph Store["ì €ì¥ì†Œ"]
        VS["ğŸ’¾ Vector Store<br/>LanceDB/Azure<br/>ì¸ë±ì‹±"]
    end

    subgraph Search["ê²€ìƒ‰ ë‹¨ê³„"]
        Q["â“ Query"]
        QE["ğŸ”¤ ì¿¼ë¦¬ í† í°í™”"]
        QE2["ğŸ”„ ì¿¼ë¦¬ ì„ë² ë”©"]
        SIM["ğŸ“Š ìœ ì‚¬ë„ ê³„ì‚°<br/>Cosine Similarity"]
        TOP["ğŸ¯ Top-K Results"]
    end

    T --> TOKEN --> EMBED --> NORM --> VS
    E --> TOKEN
    C --> TOKEN

    Q --> QE --> QE2 --> SIM --> TOP

    style Input fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style Encode fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style Store fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style Search fill:#fce4ec,stroke:#c2185b,stroke-width:2px
```

### ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```mermaid
flowchart LR
    A["ì›ë³¸ í…ìŠ¤íŠ¸<br/>'GraphRAG is...'"] --> B[í† í°í™”<br/>[1234, 5678, ...]]

    B --> C[ì„ë² ë”© ëª¨ë¸<br/>text-embedding-3-small]

    C --> D["ë²¡í„° ì¶œë ¥<br/>[0.1, -0.3, 0.8, ...]<br/>1536 ì°¨ì›"]

    D --> E[L2 ì •ê·œí™”<br/>ë‹¨ìœ„ ë²¡í„°]

    E --> F[ë²¡í„° DB ì €ì¥]

    style A fill:#e1f5fe
    style B fill:#fff9c4
    style C fill:#c8e6c9
    style D fill:#e1bee7
    style E fill:#ffccbc
    style F fill:#fff59d
```

## ğŸ“Š ì„ë² ë”© ëª¨ë¸

### OpenAI Embeddings

| ëª¨ë¸ | ì°¨ì› | ì„±ëŠ¥ | ë¹„ìš© | ì†ë„ |
|------|------|------|------|------|
| `text-embedding-3-small` | 1536 | ìš°ìˆ˜ â­â­â­â­ | ë‚®ìŒ ğŸ’° | ë¹ ë¦„ âš¡ |
| `text-embedding-3-large` | 3072 | ìµœìƒ â­â­â­â­â­ | ì¤‘ê°„ ğŸ’°ğŸ’° | ì¤‘ê°„ âš¡âš¡ |
| `text-embedding-ada-002` | 1536 | ì¢‹ìŒ â­â­â­ | ë‚®ìŒ ğŸ’° | ë¹ ë¦„ âš¡ |

### ëª¨ë¸ ë¹„êµ ì‹œê°í™”

```mermaid
flowchart TB
    subgraph Small["text-embedding-3-small"]
        S1["âœ… 1536 ì°¨ì›"]
        S2["âœ… ë¹ ë¥¸ ê²€ìƒ‰"]
        S3["âœ… ë‚®ì€ ì €ì¥ ë¹„ìš©"]
        S4["âš ï¸ ì•½ê°„ ë‚®ì€ í‘œí˜„ë ¥"]
    end

    subgraph Large["text-embedding-3-large"]
        L1["âœ… 3072 ì°¨ì›"]
        L2["âœ… ë›°ì–´ë‚œ í‘œí˜„ë ¥"]
        L3["âœ… ë¯¸ì„¸í•œ ì°¨ì´ êµ¬ë¶„"]
        L4["âš ï¸ ëŠë¦° ê²€ìƒ‰"]
        L5["âš ï¸ ë†’ì€ ì €ì¥ ë¹„ìš©"]
    end

    style Small fill:#c8e6c9
    style Large fill:#e1bee7
```

### ì°¨ì› ì„ íƒ ê°€ì´ë“œ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  1536 ì°¨ì› (small)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ì¥ì : âœ… ë¹ ë¥¸ ê²€ìƒ‰                                 â”‚
â”‚        âœ… ë‚®ì€ ì €ì¥ ë¹„ìš©                            â”‚
â”‚        âœ… ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©                          â”‚
â”‚  ë‹¨ì : âš ï¸  ì•½ê°„ ë‚®ì€ í‘œí˜„ë ¥                         â”‚
â”‚  ì¶”ì²œ: ğŸ“Œ ì¼ë°˜ì ì¸ ë¬¸ì„œ ê²€ìƒ‰                         â”‚
â”‚        ğŸ“Œ ì‹¤ì‹œê°„ ê²€ìƒ‰ ì‹œìŠ¤í…œ                         â”‚
â”‚        ğŸ“Œ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  3072 ì°¨ì› (large)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ì¥ì : âœ… ë›°ì–´ë‚œ í‘œí˜„ë ¥                             â”‚
â”‚        âœ… ë¯¸ì„¸í•œ ì°¨ì´ êµ¬ë¶„                           â”‚
â”‚        âœ… ë³µì¡í•œ ì˜ë¯¸ ì´í•´                           â”‚
â”‚  ë‹¨ì : âš ï¸  ëŠë¦° ê²€ìƒ‰                                 â”‚
â”‚        âš ï¸  ë†’ì€ ì €ì¥ ë¹„ìš©                            â”‚
â”‚        âš ï¸  ë§ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©                          â”‚
â”‚  ì¶”ì²œ: ğŸ“Œ ì •ë°€í•œ ì˜ë¯¸ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°             â”‚
â”‚        ğŸ“Œ ì „ë¬¸ ë„ë©”ì¸                               â”‚
â”‚        ğŸ“Œ ì‘ì€ ê·œëª¨ ë°ì´í„°ì…‹                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” ì„ë² ë”© ì „ëµ

### 1. í…ìŠ¤íŠ¸ ì²­í¬ ì„ë² ë”©

```mermaid
flowchart LR
    A[ë¬¸ì„œ] --> B[ì²­í‚¹<br/>~2000 í† í°]
    B --> C1[ì²­í¬ 1]
    B --> C2[ì²­í¬ 2]
    B --> C3[ì²­í¬ N]

    C1 --> E1[ì„ë² ë”© 1]
    C2 --> E2[ì„ë² ë”© 2]
    C3 --> E3[ì„ë² ë”© N]

    E1 --> V[ë²¡í„° DB]
    E2 --> V
    E3 --> V

    style A fill:#e1f5fe
    style C1 fill:#fff9c4
    style C2 fill:#fff9c4
    style C3 fill:#fff9c4
    style V fill:#c8e6c9
```

```python
async def embed_text_units(
    text_units: pd.DataFrame,
    embed_model: BaseEmbeddingModel,
    batch_size: int = 100
) -> np.ndarray:
    """
    í…ìŠ¤íŠ¸ ì²­í¬ ì„ë² ë”©
    """
    embeddings = []

    for i in range(0, len(text_units), batch_size):
        batch = text_units.iloc[i:i+batch_size]

        # ë°°ì¹˜ ì„ë² ë”©
        batch_embeddings = await embed_model.embed_batch(
            texts=batch['text'].tolist()
        )
        embeddings.extend(batch_embeddings)

    return np.array(embeddings)
```

### 2. ì—”í‹°í‹° ì„¤ëª… ì„ë² ë”©

```mermaid
flowchart TB
    A[ì—”í‹°í‹° ëª©ë¡] --> B[ì„¤ëª… í…ìŠ¤íŠ¸ êµ¬ì„±]

    B --> C1["Microsoft:<br/>ì£¼ìš” ê¸°ìˆ  íšŒì‚¬"]
    B --> C2["OpenAI:<br/>AI ì—°êµ¬ ê¸°ê´€"]
    B --> C3["GPT-4:<br/>ì–¸ì–´ ëª¨ë¸"]

    C1 --> E1[ì„ë² ë”© 1]
    C2 --> E2[ì„ë² ë”© 2]
    C3 --> E3[ì„ë² ë”© 3]

    E1 --> M[ì—”í‹°í‹°-ì„ë² ë”© ë§¤í•‘]
    E2 --> M
    E3 --> M

    style A fill:#e1f5fe
    style B fill:#fff9c4
    style M fill:#c8e6c9
```

```python
def embed_entities(
    entities: pd.DataFrame,
    embed_model: BaseEmbeddingModel
) -> dict[str, np.ndarray]:
    """
    ì—”í‹°í‹° ì„¤ëª… ì„ë² ë”©
    """
    # ì„¤ëª… í…ìŠ¤íŠ¸ êµ¬ì„±
    texts = [
        f"{e['title']}: {e['description']}"
        for _, e in entities.iterrows()
    ]

    # ì„ë² ë”©
    embeddings = embed_model.embed_batch(texts)

    # ë§¤í•‘
    return {
        entity_id: emb
        for entity_id, emb in zip(entities['id'], embeddings)
    }
```

### 3. ì»¤ë®¤ë‹ˆí‹° ì»¨í…ìŠ¤íŠ¸ ì„ë² ë”©

```mermaid
flowchart TB
    A[ì»¤ë®¤ë‹ˆí‹°] --> B[ì—”í‹°í‹° ìˆ˜ì§‘]

    B --> C["ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±<br/>- ì»¤ë®¤ë‹ˆí‹° ì´ë¦„<br/>- ì—”í‹°í‹° ëª©ë¡<br/>- ì„¤ëª… ìš”ì•½"]

    C --> D[ì„ë² ë”© ìƒì„±]

    D --> E[ì»¤ë®¤ë‹ˆí‹° ì„ë² ë”©]

    style A fill:#e1f5fe
    style C fill:#fff9c4
    style E fill:#c8e6c9
```

```python
def embed_community_contexts(
    communities: pd.DataFrame,
    entities: pd.DataFrame,
    embed_model: BaseEmbeddingModel
) -> dict[str, np.ndarray]:
    """
    ì»¤ë®¤ë‹ˆí‹° ì „ì²´ ì»¨í…ìŠ¤íŠ¸ ì„ë² ë”©
    """
    context_embeddings = {}

    for _, community in communities.iterrows():
        # ì»¤ë®¤ë‹ˆí‹° ì—”í‹°í‹° ìˆ˜ì§‘
        comm_entities = entities[
            entities['community_id'] == community['id']
        ]

        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        entity_names = comm_entities['title'].tolist()
        entity_desc = comm_entities['description'].tolist()

        context_text = f"""
        Community: {community['title']}
        Entities: {', '.join(entity_names)}
        Descriptions: {' | '.join(entity_desc[:5])}
        """

        # ì„ë² ë”©
        embedding = embed_model.embed(context_text)
        context_embeddings[community['id']] = embedding

    return context_embeddings
```

## ğŸ“ ìœ ì‚¬ë„ ê³„ì‚°

### ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (Cosine Similarity)

```mermaid
flowchart TB
    A["ë²¡í„° A<br/>[0.8, 0.3, 0.9]"]
    B["ë²¡í„° B<br/>[0.7, 0.4, 0.85]"]

    A --> DOT["ë‚´ì  ê³„ì‚°<br/>A Â· B = Î£(ai Ã— bi)"]
    B --> DOT

    A --> NORM["ë…¸ë¦„ ê³„ì‚°<br/>||A|| = âˆš(Î£aiÂ²)"]
    B --> NORM

    DOT --> COS["cos(Î¸) = (A Â· B) / (||A|| Ã— ||B||)"]
    NORM --> COS

    COS --> RESULT["ìœ ì‚¬ë„ ì ìˆ˜<br/>0.97 (ë§¤ìš° ìœ ì‚¬)"]

    style A fill:#e1f5fe
    style B fill:#e1bee7
    style RESULT fill:#c8e6c9
```

ê°€ì¥ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ìœ ì‚¬ë„ ë©”íŠ¸ë¦­:

```python
import numpy as np

def cosine_similarity(
    a: np.ndarray,
    b: np.ndarray
) -> float:
    """
    ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    """
    # ë‚´ì 
    dot_product = np.dot(a, b)

    # ë…¸ë¦„
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)

    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
    return dot_product / (norm_a * norm_b)
```

### ìœ ì‚¬ë„ ì ìˆ˜ í•´ì„

```mermaid
flowchart TB
    S1["0.9 - 1.0<br/>ë§¤ìš° ìœ ì‚¬<br/>ë™ì¼í•œ ì˜ë¯¸"]
    S2["0.7 - 0.9<br/>ìœ ì‚¬<br/>ê´€ë ¨ ì£¼ì œ"]
    S3["0.5 - 0.7<br/>ì•½ê°„ ìœ ì‚¬<br/>ê°„ì ‘ì  ì—°ê´€"]
    S4["0.3 - 0.5<br/>ê±°ì˜ ê´€ë ¨ ì—†ìŒ"]
    S5["0.0 - 0.3<br/>ì „í˜€ ë‹¤ë¥¸ ì£¼ì œ"]

    style S1 fill:#c8e6c9
    style S2 fill:#a5d6a7
    style S3 fill:#fff59d
    style S4 fill:#ffccbc
    style S5 fill:#ffcdd2
```

### ë‹¤ë¥¸ ìœ ì‚¬ë„ ë©”íŠ¸ë¦­

| ë©”íŠ¸ë¦­ | ê³µì‹ | íŠ¹ì§• | ì‚¬ìš© ì‚¬ë¡€ |
|--------|------|------|----------|
| **Cosine** | AÂ·B / (\|A\|\|B\|) | ë°©í–¥ë§Œ, í¬ê¸° ë¬´ì‹œ | í…ìŠ¤íŠ¸ ì„ë² ë”© |
| **Euclidean** | âˆš(Î£(a-b)Â²) | ê±°ë¦¬ ê¸°ë°˜ | ì´ë¯¸ì§€ ì„ë² ë”© |
| **Dot Product** | AÂ·B | ì›ì  ê¸°ë°˜ | ì •ê·œí™”ëœ ë²¡í„° |

## ğŸ” ë²¡í„° ê²€ìƒ‰

### Top-K ê²€ìƒ‰

```mermaid
flowchart TB
    A["ì¿¼ë¦¬: 'AI ê¸°ìˆ '"] --> B[ì¿¼ë¦¬ ì„ë² ë”©]

    B --> C[ë²¡í„° DB]

    C --> D["ëª¨ë“  ë¬¸ì„œì™€<br/>ìœ ì‚¬ë„ ê³„ì‚°"]

    D --> E[ìƒìœ„ Kê°œ ì¶”ì¶œ]

    E --> F["ê²°ê³¼: 1. GPT (0.95)<br/>      2. BERT (0.92)<br/>      3. AI (0.88)"]

    style A fill:#e1f5fe
    style B fill:#fff9c4
    style F fill:#c8e6c9
```

```python
def vector_search(
    query_embedding: np.ndarray,
    index: np.ndarray,  # (N, D) ì„ë² ë”© í–‰ë ¬
    k: int = 10
) -> list[tuple[int, float]]:
    """
    Top-K ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
    """
    # ëª¨ë“  ë¬¸ì„œì™€ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = cosine_similarity_matrix(query_embedding, index)

    # ìƒìœ„ Kê°œ ì¶”ì¶œ
    top_k_indices = np.argsort(similarities)[::-1][:k]

    return [
        (idx, similarities[idx])
        for idx in top_k_indices
    ]
```

### ANN (Approximate Nearest Neighbor)

ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œëŠ” ì •í™•í•œ ê²€ìƒ‰ ëŒ€ì‹  ê·¼ì‚¬ ê²€ìƒ‰ ì‚¬ìš©:

```mermaid
flowchart TB
    subgraph Exact["ì •í™• ê²€ìƒ‰"]
        E1["ëª¨ë“  ë²¡í„°ì™€ ë¹„êµ"]
        E2["O(N) ë³µì¡ë„"]
        E3["ì •í™•í•˜ì§€ë§Œ ëŠë¦¼"]
    end

    subgraph ANN["ê·¼ì‚¬ ê²€ìƒ‰"]
        A1["ì¸ë±ìŠ¤ ê¸°ë°˜ ê²€ìƒ‰"]
        A2["O(log N) ë³µì¡ë„"]
        A3["ë¹ ë¥´ì§€ë§Œ ì•½ê°„ ë¶€ì •í™•"]
    end

    style Exact fill:#ffcdd2
    style ANN fill:#c8e6c9
```

```python
import lancedb

def create_vector_index():
    """LanceDB ì¸ë±ìŠ¤ ìƒì„±"""
    db = lancedb.connect("./output/lancedb")

    # í…Œì´ë¸” ìƒì„± (IVF_FLAT ì¸ë±ìŠ¤)
    db.create_table(
        "embeddings",
        data=[
            {
                "id": i,
                "vector": embedding,
                "text": text
            }
            for i, (embedding, text) in enumerate(zip(embeddings, texts))
        ]
    )

    # IVF_FLAT ì¸ë±ìŠ¤ ìƒì„±
    db.create_index(
        "embeddings",
        vector_column_name="vector",
        index_type="IVF_FLAT",
        metric="cosine"
    )
```

### ANN ê²€ìƒ‰ ì„±ëŠ¥ ë¹„êµ

| ë°ì´í„° í¬ê¸° | ì •í™• ê²€ìƒ‰ | ANN ê²€ìƒ‰ | ì†ë„ í–¥ìƒ |
|-----------|----------|----------|-----------|
| 1K | 5ms | 1ms | 5x |
| 10K | 50ms | 5ms | 10x |
| 100K | 500ms | 50ms | 10x |
| 1M | 5000ms | 200ms | 25x |

## ğŸ“ ì„ë² ë”© ìµœì í™”

### 1. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰

```mermaid
flowchart TB
    Q[ì¿¼ë¦¬] --> K[í‚¤ì›Œë“œ ê²€ìƒ‰<br/>BM25]
    Q --> V[ë²¡í„° ê²€ìƒ‰<br/>ì„ë² ë”©]

    K --> RRF[Reciprocal Rank Fusion]
    V --> RRF

    RRF --> FINAL[ê²°ê³¼ ë³‘í•©]

    style Q fill:#e1f5fe
    style K fill:#fff9c4
    style V fill:#c8e6c9
    style FINAL fill:#e1bee7
```

```python
def hybrid_search(
    query: str,
    alpha: float = 0.5  # í‚¤ì›Œë“œ vs ë²¡í„° ê°€ì¤‘ì¹˜
) -> list[dict]:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í‚¤ì›Œë“œ + ë²¡í„°)
    """
    # 1. í‚¤ì›Œë“œ ê²€ìƒ‰
    keyword_results = bm25_search(query)

    # 2. ë²¡í„° ê²€ìƒ‰
    vector_results = vector_search(query)

    # 3. ê²°ê³¼ ê²°í•© (Reciprocal Rank Fusion)
    scores = {}

    for rank, doc in enumerate(keyword_results):
        scores[doc['id']] = scores.get(doc['id'], 0) + 1 / (rank + 1)

    for rank, doc in enumerate(vector_results):
        scores[doc['id']] = scores.get(doc['id'], 0) + 1 / (rank + 1)

    # 4. ì •ë ¬
    sorted_results = sorted(scores.items(), key=lambda x: -x[1])

    return sorted_results
```

### 2. ì¿¼ë¦¬ í™•ì¥

```mermaid
flowchart LR
    A[ì›ë³¸ ì¿¼ë¦¬<br/>'AI ê¸°ìˆ '] --> B[ê´€ë ¨ ì—”í‹°í‹° ì¶”ì¶œ<br/>GPT, BERT, ML]

    B --> C["í™•ì¥ëœ ì¿¼ë¦¬ ë²¡í„°<br/>= 0.7 Ã— ì›ë³¸<br/>  + 0.3 Ã— ì—”í‹°í‹°ë“¤"]

    C --> D[ê°œì„ ëœ ê²€ìƒ‰]

    style A fill:#e1f5fe
    style C fill:#fff9c4
    style D fill:#c8e6c9
```

```python
def expand_query_embedding(
    query: str,
    entities: list[Entity],
    embed_model: BaseEmbeddingModel
) -> np.ndarray:
    """
    ê´€ë ¨ ì—”í‹°í‹°ë¡œ ì¿¼ë¦¬ ì„ë² ë”© ê°•í™”
    """
    # ì›ë³¸ ì¿¼ë¦¬ ì„ë² ë”©
    query_emb = embed_model.embed(query)

    # ê´€ë ¨ ì—”í‹°í‹° ì„ë² ë”©
    entity_embs = [
        embed_model.embed(f"{e['title']}: {e['description']}")
        for e in entities[:5]  # ìƒìœ„ 5ê°œ
    ]

    # ê°€ì¤‘ í‰ê· 
    alpha = 0.7  # ì¿¼ë¦¬ ê°€ì¤‘ì¹˜
    beta = 0.3   # ì—”í‹°í‹° ê°€ì¤‘ì¹˜

    expanded_emb = alpha * query_emb + beta * np.mean(entity_embs, axis=0)

    # ì¬ì •ê·œí™”
    return expanded_emb / np.linalg.norm(expanded_emb)
```

### 3. ì„ë² ë”© ìºì‹±

```python
import pickle

class EmbeddingCache:
    def __init__(self, cache_path: str):
        self.cache_path = cache_path
        self.cache = self._load_cache()

    def get(self, text: str) -> np.ndarray | None:
        return self.cache.get(text)

    def set(self, text: str, embedding: np.ndarray):
        self.cache[text] = embedding
        with open(self.cache_path, 'wb') as f:
            pickle.dump(self.cache, f)
```

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

| ì‘ì—… | ì‘ì€ í¬ê¸° (< 1K) | ì¤‘ê°„ í¬ê¸° (10K) | í° í¬ê¸° (100K+) |
|------|-------------------|-------------------|-------------------|
| **ì„ë² ë”©** | 1-2ì´ˆ | 10-20ì´ˆ | 2-5ë¶„ |
| **ì •í™• ê²€ìƒ‰** | < 1ms | 10-50ms | 100-500ms |
| **ANN ê²€ìƒ‰** | < 1ms | 5-20ms | 50-200ms |
| **ì €ì¥ì†Œ** | 10MB | 100MB | 1GB+ |

## ğŸ”— ê´€ë ¨ ì»´í¬ë„ŒíŠ¸

- [[Storage Module]]: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
- [[Text Unit]]: í…ìŠ¤íŠ¸ ì„ë² ë”© ëŒ€ìƒ
- [[Entity]]: ì—”í‹°í‹° ì„ë² ë”©
- [[Local Search]]: ì„ë² ë”© í™œìš© ê²€ìƒ‰

## ğŸ’¡ ì„±ëŠ¥ ìµœì í™” íŒ

1. **ë°°ì¹˜ ì²˜ë¦¬**: í•œ ë²ˆì˜ API í˜¸ì¶œë¡œ ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì²˜ë¦¬
2. **ìºì‹±**: ë™ì¼í•œ í…ìŠ¤íŠ¸ ì¬ì„ë² ë”© ë°©ì§€
3. **ANN ì¸ë±ìŠ¤**: ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ ê·¼ì‚¬ ê²€ìƒ‰ ì‚¬ìš©
4. **ì°¨ì› ì¶•ì†Œ**: í•„ìš”í•œ ê²½ìš° ì°¨ì› ì¶•ì†Œë¡œ ì €ì¥ ë¹„ìš© ì ˆê°

---
*See also: [[Storage Module]], [[Local Search]], [[Text Unit]]*
